---
title: "Note"
format: html
editor_options: 
  chunk_output_type: console
---

# library
```{r}
library(tidyverse)
library(dplyr)
library(fable)
library(fpp3)
library(GGally)
library(feasts)
library(slider)
```


# eaxm note---------------------------------------------------

```{r}
# tsibble


# tsibble( colname = c(), colname = c(), index= one variable)

# as_tsibble(index = variable name, key=c()) #trans df into tsdf, must indicate the index variable
#Key variable(s) together with the index uniquely identifies each record:

# distincet() similar to unique()

#






```
--------------------------------------------------------------

# 1 geting started
## 1.4 forecasting data and methods

Quantitative forecasting can be applied when two conditions are satisfied:

1. numerical information about the past is available;
2. it is reasonable to assume that some aspects of the past patterns will continue into the future.

## 1.6 the basic steps in a forecasting task

1. problem difinition
2. gathering information
3. preliminary analysis
4. choosing and fitting models
5. using and evaluating a forecasting model

# 2 time series graphics

## 2.3 time series parrerns

trend: long-term

seasonal: A seasonal pattern occurs when a time series is affected by seasonal factors such as the time of the year or the day of the week. Seasonality is always of a fixed and known period.

cyclic: A cycle occurs when the data exhibit rises and falls that are not of a fixed frequency.

## plots

```{r}

# ordinary
#%>%
#  autoplot(df,variable)%>%
#  labs(title="", subtitle="",y="")


# seasonal
#df%>%
#  gg_season(variable, labels = "")+
#  labs(y = "".
#       title = "")


# mutliple seasonal periods
# 意味着原始数据颗粒度很细的时候，我们可以选择不同的pattern去聚合

#  gg_season(variable, period = "")+
#  labs(y = "".
#       title = "")


# seasonal subseries plot

#  gg_subseries(variable)+
#  labs(y = "".
#       title = "")
# 实现同比 （例如不同年份的同一月份的比对）


# lag

# df%>%
# gg+lag(varable, geom= c("point","line")+
# labs()



```

## autocorrelation

```{r}
# ACF(variable, lag_max = number)%>%
# autp_plot()




```

## 2.9 white noise


For a white noise series, we expect 95% of the spikes in the ACF to lie within +-2/squrt(T)  where T is the length of the time series. It is common to plot these bounds on a graph of the ACF (the blue dashed lines above). If one or more large spikes are outside these bounds, or if substantially more than 5% of spikes are outside these bounds, then the series is probably not white noise.

## 2.10 exercises

```{r}

```



# 3 time series decomposition

## 3.1 transformations and adjustments

1. Calendar adjustments
Some of the variation seen in seasonal data may be due to simple calendar effects. In such cases, it is usually much easier to remove the variation before doing any further analysis.
每个月工作日数量不一样导致的差异，可以通过求平均值来规避

2. population adjustments
Any data that are affected by population changes can be adjusted to give per-capita data. 
和calendar adjustments原理一致。求平均。

3. inflation adjustments
Data which are affected by the value of money are best adjusted before modelling. 
To make these adjustments, a price index is used. If zt denotes the price index and yt denotes the original house price in year t, then xt=yt/zt∗z2000 gives the adjusted house price at year 2000 dollar values. Price indexes are often constructed by government agencies. For consumer goods, a common price index is the Consumer Price Index (or CPI).

4. mathematical transformations

If the data shows *variation that increases or decreases with the level* of the series, then a transformation can be useful.


## 3.2 time series components

S: seasonal component
T: trend-cycle component
R: reminder component

additive decomposition:
y = s+t+r

multiplicative decomposition:
y = s*T*R
or
log(y) = log(s)+log(t)+log(r)

The additive decomposition is the most appropriate if the magnitude of the seasonal fluctuations, or the variation around the trend-cycle, does not vary with the level of the time series. When the variation in the seasonal pattern, or the variation around the trend-cycle, appears to be proportional to the level of the time series, then a multiplicative decomposition is more appropriate. Multiplicative decompositions are common with economic time series.

```{r}
#model <- df%>%
#model(stl = STL(df))

#components(model)

#plot
#components(model)%>%
# as.tsibble()%>%
# autoplot()%>%
# geom_line(aes(y = trend),colour=)%>% adding trend line
# labs()

#or plot as facet plots
#components(model)%>%autoplot()

```

### seasonally adjusted data

If the seasonal component is removed from the original data, the resulting values are the “seasonally adjusted” data.

Seasonally adjusted series contain the remainder component as well as the trend-cycle. Therefore, they are not “smooth”, and “downturns” or “upturns” can be misleading. If the purpose is to look for turning points in a series, and interpret any changes in direction, then it is better to use the trend-cycle component rather than the seasonally adjusted data.

## 3.3 moving average

```{r}
# df%>%
# mutate(5ma = slider_dbl(variable,mean,.before = ,.after = ,.complete=T))

```


### moving average of moving agverages

usally m is a odd number. Consiser if it is a even number.

### weighted moving averages

A major advantage of weighted moving averages is that they yield a smoother estimate of the trend-cycle. Instead of observations entering and leaving the calculation at full weight, their weights slowly increase and then slowly decrease, resulting in a smoother curve.

## 3.4 classical decomposition

While classical decomposition is still widely used, it is not recommended, as there are now several much better methods.

## 3.5 methods used by official statistics agencies

### x-11 method

### seats method

## 3.5 STL
“Seasonal and Trend decomposition using Loess”, while loess is a method for estimating nonlinear relationships. 

On the other hand, STL has some disadvantages. In particular, it does not handle trading day or calendar variation automatically, and it only provides facilities for additive decompositions.
A multiplicative decomposition can be obtained by first taking logs of the data, then back-transforming the components.
Decompositions that are between additive and multiplicative can be obtained using a Box-Cox transformation of the data with  
0<λ<1. A value of  λ=0 gives a multiplicative decomposition while  
λ=1 gives an additive decomposition.

```{r}
# df%>%
#  model( 
#   STL(col ~ trend( window = 7)+
#             season(window = "periodic"),
#        robust = T))%>%
# components()%>%
# autoplot()
```
The two main parameters to be chosen when using STL are the trend-cycle window trend(window = ?) and the seasonal window season(window = ?). These control how rapidly the trend-cycle and seasonal components can change. 
Setting the seasonal window to be infinite is equivalent to forcing the seasonal component to be periodic season(window='periodic')
By default, the STL() function provides a convenient automated STL decomposition using a seasonal window of season(window=13), and the trend window chosen automatically from the seasonal period. The default setting for monthly data is trend(window=21).
 This usually gives a good balance between overfitting the seasonality and allowing it to slowly change over time.





# seasonal arima


p d q . d denotes the difference / differencing
```{r}

leisure = us_employment%>%
  filter(Title == "Leisure and Hospitality",
         year(Month) > 2000)%>%
  mutate(Employed = Employed/1000)%>%
  select(Month, Employed)


leisure %>%
  gg_tsdisplay(difference(Employed,12),
               plot_type="partial",lag=36) # 36 indicates 3 years

leisure %>%
  gg_tsdisplay(difference(Employed,12)%>%difference(),
               plot_type="partial",lag=36) # 36 indicates 3 years



fit = leisure %>%
  model(
    arima012011 = ARIMA(Employed ~ pdq(0,1,2)+PDQ(0,1,2)),
    arima210110 = ARIMA(Employed ~ pdq(2,1,0)+PDQ(1,1,0)),
    auto = ARIMA(Employed,stepwise = F, approximation = F) # base on the aicc
  )

fit %>% pivot_longer(everything())


fit %>% glance()%>% gg_tsresiduals(lag =  ) # to see the residuals

# auto returns to a better result

fit %>% select(auto)%>%gg_tsresiduals(lag = 36)

augment(fit)%>%
  filter(.model== 'auto')%>%
  features(.innov, ljung_box,lag=24, dof= 4)

forecast(fit,h=36)%>% filter(.model == 'auto')%>%
  autoplot(leisure)


```



```{r}
#compare models by aicc when difference is same both in trend and season

# if difference is changed, then we should split data into train and test, and then compare the models
# but we can not subset sample randomly, slice data by a specific date.


# using glance instead of summary() ? note fot the mater thesis. or maybe report()
# try different functions

# also accurancy() then calculate rsme step by step


# use it to determein how many seaons should we include
#  df %>%
#       features(col,unitroot_nsdiffs)

# returns 1 (12months in this case)

# and test 

#  df %>%
#       features(diffence(col,12),unitroot_nsdiffs)

```






































